{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Colab\n",
    "\n",
    "Hi everyone. This is a **colab**oratory document. This is the main writing and programming environment we'll be working with in this course. There are few things to notice. First, we have a table of contents on the left that you can toggle. This will make it easy for you to navigate the notes I write but also the notes you write in colab. \n",
    "\n",
    "Second, if you double click on this text, the cell will change into an editable, markdown form. That means you can annotate the notes directly. You only see a local copy so changes you make are private to you. The text processing language is called Markdown. You don't need to know much about markdown to navigate this class but if you want to learn a few things about it, it can help you organize and style your notes.\n",
    "\n",
    "Third, there are two bottoms in the top left, `+ code` and `+ text`. This let you add new cells to a colab document. Today we'll only be dealing with text. But starting next monday, we'll start writing and running code. So when you want to start writing a new idea or a new program, just add a cell and get started.\n",
    "\n",
    "Finally, you can you can save personal copies of the notes in Google drive (or Github if you have it). Or you can download them as `.ipynb` documents. Your computer can read those documents if you have already installed the Anacondas distribution and you launch Juypter notebooks on your machine. Otherwise, you can just upload the document to colab later if you want to make changes or view it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swans\n",
    "\n",
    "![](swans.jpg)\n",
    "\n",
    "Stanley park used to be the home to a large population of swans. In the 1960s, when Vancouver was still a hippie city, there were about 70 swans living in and around the Lost Lagoon. Their numbers steadily decline over the years. The last 3 Stanley Park swans were moved to a sanctuary in 2016. Suppose you're an ornithologist living in the heyday of Stanley Park swans. You are obsessed with the color of swans. Every day you go to the park and observe swans. Every swan you observe is white. It's consistent. Day after day. Swan after swan. All white. You begin to think that all swans are white. \n",
    "\n",
    "Our question is, is that a good inference? It certainly seems like a natural style of reasoning. We often observe that something happens consistently and extrapolate that it always or usually happens that way. But the fact that we make this kind of inference consistently is no indication that we *should*. Philosophers call this type of inference an *inductive* inference. It's a little hard to define in a way that is simultaneously precise, intuitive, and doesn't bias the philosophical questions we are about to explore. But for now, let's think of induction as *generalizing from examples*. \n",
    "\n",
    "One very famous philosophy had an extremely surprising view on induction. David Hume, writing in the 1700s, argued that all inductive inferences are logical fallacies. The fact that we observe one white swan is no evidence at all for the claim that all swans are white. Let's appreciate how strong Hume's claim is by contrasting a couple of things Hume isn't worried about.\n",
    "\n",
    "* He isn't saying that a single white swan isn't very good evidence for our claim. He is saying it's just not evidence at all. If you showed Hume 100 white swans, he wouldn't be moved. \n",
    "\n",
    "* He isn't saying that our hypothesis is only weakly supported. Sometimes people hear what Hume is saying and agree because we can never be certain that all swans are white. But Hume isn't worried about certainty and uncertainty. He is worried about something more simple: is it any evidence at all?\n",
    "\n",
    "Now that's a very extreme position! Induction, or generalizing from examples, seems to be something we get up to all the time. Yet this philosopher won't buy it. It turns out that Hume actually had very good and subtle reasons for his view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalizing induction\n",
    "\n",
    "Sometimes it can be helpful to formalize arguments to help us see clearly exactly how each piece goes together. Logical formalisms are tools for helping you see problems in different ways. Natural English is messy. It is full of quirky details and inconsistent ways of describing things. Most of the time, that's fine. But occasionally, we want to abstract away from their quirks so we can spot patterns. So to understand Hume's argument clearly, we are going to employ formal logic.\n",
    "\n",
    "Suppose we have some hypothesis. Let's call it $H$. We collect some observations. We'll call them $O$. Intuitively speaking, a hypothesis is confirmed when the observations match your expectations. Logically speaking, inductive inferences looks like this:\n",
    "\n",
    "$$ H \\supset O $$\n",
    "$$ O $$\n",
    "$$ \\therefore H $$\n",
    "\n",
    "The first sentence describes what your hypothesis implies about the world. In other words, it generate expectations. The second statement affirms that the expected observations are what you actually found. The last sentence is the conclusion: the observations confirm your hypothesis.\n",
    "\n",
    "Let's fill in these variables:\n",
    "\n",
    "* All swans are white $ \\supset $ the next swan I see is white\n",
    "* In fact, the next swan I see is white\n",
    "* Therefore, swans are white\n",
    "\n",
    "The purely abstract argument and the filled in one are supposed to contain the same exact logical relationships. If the first argument is a good argument then the second one is too.\n",
    "\n",
    "However, we *know* that this abstract pattern is an invalid argument. Consider another example that fits the same pattern but is  a bad inference.\n",
    "\n",
    "* You are in Vancouver $ \\supset $ you are in Canada\n",
    "* You are in Canada\n",
    "* Therefore, You are in Vancouver\n",
    "\n",
    "We know this is a bad inference because you can be in Canada in loads of ways without being in Vancouver. For example, you could be in Surrey or Burnaby. So this demonstrates that this is an invalid pattern of argument. It's called affirming the consequent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### A quick logic refresher\n",
    "\n",
    "In case it's been a while or you haven't taken logic yet, here's what the symbols mean. Feel free to skip this section.\n",
    "\n",
    "In formal logic, we turn propositions into a letters. H might mean 'the earth revolves around the sun' and O might mean 'Mercury is in retrograde.' The little $\\supset$ symbol means 'implies.' So the first line is read as 'H implies O.' Another way of putting it is that $\\supset$ corresponds to our normal English construction 'If ... then ...'. So read altogether, the first line says roughly, \"If the earth revolves around the sun, then Mercury is in retrograde.'\n",
    "\n",
    "$O$ standing alone means we have in fact observed mercury in retrograde.\n",
    "\n",
    "The three little dots $\\therefore$ mean 'therefore.' The last line represents the conclusion to the argument, or what lines 1 and 2 imply.\n",
    "\n",
    "Three other symbols I'll use:\n",
    "\n",
    "- $\\vee$ The vee means 'or.'\n",
    "\n",
    "- $\\&$ The ampersand means 'and.' \n",
    "\n",
    "- $\\thicksim$ This tilde means 'not.'\n",
    "\n",
    "We'll also use two rules of deduction, Modus Ponens and Modus Tollens. These fancy names turn out to be quite intuitive.\n",
    "\n",
    "Modus Ponens says that if you know 'if you are in Vancouver then you are in Canada' and you know you are in Vancouver, then you can deduce that you are in Canada. In symbols:\n",
    "\n",
    "$$ V \\supset C $$\n",
    "$$ V $$\n",
    "$$ \\therefore C $$\n",
    "\n",
    "Modus Tollens is the reverse. If you know you are not in Canada, you can infer you are not in Vancouver.\n",
    "\n",
    "$$ V \\supset C $$\n",
    "$$ \\thicksim  C $$\n",
    "$$ \\therefore \\, \\thicksim V $$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem of induction\n",
    "\n",
    "The reason why the inference fails in the Canada case is shared by the reason why it fails in the swans case: The fact that your hypothesis predicts the evidence does not tell you about all the other hypotheses that could also predict the evidence as well. For example, we can imagine loads of alternative hypotheses that are consistant with observing one white swan:\n",
    "\n",
    "* All swans in Stanley park are white (but outside of Stanley park, they are other colours)\n",
    "* Most swans are white\n",
    "* All swans were white in the 1960s (but were different colours in difference decades)\n",
    "\n",
    "If anyone of these is true, you should still expect to find your evidence. But they are inconsistent with your original hypothesis about all swans. So this is one way of understanding Hume's concerns about induction. Once we formalize inductive arguments, it's clear that something is missing. Maybe we could add an extra ingredient to the argument to make it valid. But as it stands, it looks like Hume is onto something.\n",
    "\n",
    "The search for the extra ingredient is called **the problem of induction**. It's kept philosophers busy for hundreds of years. This class will not delve into all the many failed attempts to solve the problem of induction. I recommend taking a course in philosophy of science or epistemology if you want to think about this more. For us, it's a really important problem because it explains why statistics is so weird. If it was straight forward to infer from specific examples to generalizations, then statistics would be easy. Instead, we have to make all sorts of extra assumptions that turn hard inductive problems into easy deductive problems. We'll pick up on this thread in a few weeks when we look at Bayesian inference. For now, I just want you to recognize that there is a problem here and it has some essential connection to statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refutation\n",
    "\n",
    "Sometimes, it is easier to understand bad inferences by contrasting them with good inferences. Let's look at a valid form of inference used often in the sciences: refutation. When your observations refute your hypothesis, it looks like this in the language of formal logic:\n",
    "\n",
    "$$ H \\supset O $$\n",
    "$$ \\thicksim O $$\n",
    "$$ \\therefore \\, \\thicksim H $$\n",
    "\n",
    "In your logic class, it probably had the name 'Modus Tollens'. If your hypothesis, $H$, is 'the earth revolves around the sun' and you think that implies the observation, $O$, that 'Mercury is in retrograde right now,' then failing to find retrograde motion would refute your hypothesis.\n",
    "\n",
    "So maybe another easy way of appreciating why inductive inferences are invalid is to remember what their valid cousins look like. In induction, we are missing some negations that we need for a valid argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two logical approaches to science\n",
    "\n",
    "When philosophers began to notice and appreciate the problem of induction, it put science into a bit of a crisis. How could science be so successful if it's impossible to make valid inferences from samples? So philosophers went to work trying to explain this puzzle. They took two different pathes - some tried to rescue induction by finding the missing ingredient. Others tried to show that science could get the job down by refutation alone. Karl Popper is the most famous philosopher who promoted a refutation-based approach to science. What science does, in his eyes, is it comes up with a long list of theories. Then it eliminates them one-by-one. The theories that survive lots of difficult tests must by close to the truth.\n",
    "\n",
    "Karl Popper was enormously influential on science. In the 20th century, loads of scientists looked to him as a guide for what proper scientific methodology looks like. So his ideas became enshired in the introduction sections of lots of textbook. The idea that experiments are supposed to 'test' hypotheses is fairly mainstream and is part of his influence. But notice what gets left out: in every day inference, we use confirmation-style reasoning. We cannot help but generalize from examples and use a supporting example as evidence for our theories. So science was in an awkward place where the way we reason in commonsense and the way textbooks said that scientists reason were fairly different. \n",
    "\n",
    "One legacy of Popper that is particularly important to us is his influence on statistics. One of the most popular approaches to statistics focuses on \"statistical significance.\" This is a measure of how improbable the evidence is, assuming some theory called the null hypothesis. Recall the Bargh experiment about walking speeds. The null hypothesis is that the two groups aren't actually different. They have the same average walking speed. Any appearance that they have different walking speeds is due to random chance. The goal of many experiments is to achieve statistical significance and to refute a null hypothesis like this one. Significance testing is like a statistical version of refutation.\n",
    "\n",
    "Significance testing is on firm logical footing because refutation style arguments are good. But it's worth noting that this \"refutation-only\" approach to science is a bit of a let down. What I want to know is, which theory is true? If I can't have that, I want to know which theory is likely to be true. But significance testing only tells me which theories are false. So it's no surprise that statistics is pretty unintuitive. It has to avoid talking about the thing that we usually want to know.\n",
    "\n",
    "A minute ago, I noted that other philosophers tried to rescue induction. One prominent approach here is the Bayesian one. Bayesian statistics tries to figure out which theory is most probable, rather than just figuring out which theories are wrong. So these two approaches to the problem of induction have associated schools of statistical inference too. In this course, we'll be mostly focused on the Bayesian one. It's not like you have to pick aside in the rivalry. But it can be illuminating to see statistics from a different light, one that might make more sense to you, given that it recovers some features of our intuitions about induction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic as a template for scientific activities\n",
    "\n",
    "One reason why I like thinking about argument structures early in the term is that it provides a template for organizing the core scientific activities. Fundamentally, there are three activities in science - theorizing, collecting data, and inference. The correspond to the parts of argument.\n",
    "\n",
    "* $ H \\supset O $ - theorizing\n",
    "* $ O $ - collecting data\n",
    "\n",
    "and then the rules that tell us how the first line connects to the second line is inference. The main rules for this are the rules of formal logic. But, as we'll see over the next few weeks, the rules of probability theory also help us connect theories to data.\n",
    "\n",
    "Figuring out what some set of assumptions ($H$) implies about the world is the work of theorizing. In many cases, theorizing is easy. If all swans are white, that implies this swan should be white. The implication is obvious. But that's an especially easy case. For all the interesting scientific theories, it is usually not at all obvious what the assumptions imply about the world. Sometimes when we really consider the assumptions of our theory carefully, the implications are suprising. \n",
    "\n",
    "Fortunately, we have tools for figuring out what theories imply about the world. Those tools are models - ways of structuring assumptions together so they make clear and interpretation implication. Modeling also lets us play with our assumptions - we can vary assumptions and see our the implications change. This skill is the main focus of our course.\n",
    "\n",
    "Finally, we have the data itself. This class will not spend a lot of time talking about the practical skills of collecting data. How to collect brain scan data is a topic of its own. How to write good surveys is another topic. So there is very little I can say about data collection that will apply to all the diverse fields you might go into. But I can offer you something else: sometimes the data we collect cannot answer the question we are trying to answer. A lot of the time, we only find out that our data can't answer that question as we wasted a bunch of time collecting it. I can help this way: if you have a clear model of your experiment, you can generate simulated data ahead of time. Then you find out whether the data even offer the possibility of answering your question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

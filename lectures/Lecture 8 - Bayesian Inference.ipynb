{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33b4f83",
   "metadata": {
    "id": "b33b4f83"
   },
   "source": [
    "# Overview\n",
    "\n",
    "A few weeks ago we talked about Karl Popper's approach to science and noted that significance testing is pretty similar. Both put the emphasis on rejecting bad theories but don't seem too interested in confirming or identifying the true theories. Moreover, they don't have any way of saying which theories are most likely to be true.\n",
    "\n",
    "This is disappointing. Don't we want to know which of our theories is the best one? Giving up on any sense of ranking between undefeated theories is a big cost. Imagine we're climate scientists. We develop a big batch of climate models based on various theories. Then we do as Popper suggests and start eliminating them. After a while, we have two climate models left. One of them says everything in the near future will be fine. The other predicts catastrophic climate change. \n",
    "\n",
    "Now governments are consulting with us about infrastructure, energy and disaster policy. They want to know which model is more credible. But if Popper's right, we cannot answer this question. All we can say is that these two model both stand unrefuted. The government officials leave and so does our funding. Science that can't rationally inform predictions may not be worth pursuing.\n",
    "\n",
    "Today, we'll explore Bayesian statistics, an approach that can avoid the problem of rational prediction. For the most part, I think Bayesian statistics is a big improvement over significance testing. It can make good predictions, it's simpler, it's logically very elegant, it's more informative. These benefits come at two small costs. First, it requires even more assumptions, assumptions that some worry introduce too much subjectivity. Second, it's computationally intensive. We'll work on problems where you computer will just hum for 2 minutes before finding the solution.\n",
    "\n",
    "Today, we'll just introduce the mathematics, work through a couple problems, turn to posterior distributions and spend the whole class just exploring how they work. Next time, we'll turn to some the philosophical advantages and criticisms of the approach alongside a couple of more complex problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v11WZc7ZARzk",
   "metadata": {
    "id": "v11WZc7ZARzk"
   },
   "source": [
    "\n",
    "# Bayes Theorem\n",
    "\n",
    "One point I've tried to emphasize in discussing p-values is that they do not tell you the probability your hypothesis is true. They just tell you the probability of the data given the hypothesis, or $P(E|H)$. This feels disastifying. What we really want to know is how good our hypothesis is, or $P(H|E)$. This isn't a small complaint. Unless we have a way to measure $P(H|E)$, it seems hard for science to progress toward the truth. Surely, there must be a way to infer how probable a hypothesis is from how probable the data are!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pTGxWwLEAn2I",
   "metadata": {
    "id": "pTGxWwLEAn2I"
   },
   "source": [
    "## Likelihoods are not posteriors\n",
    "\n",
    "Unfortunately, the relationship is not straightforward. Here is a simple example to prime your intuition. Suppose you're complaining to your friend about how rainy it's been lately. Your friend replies, \"well, it is March after all.\" Your friend has just done a tiny bit of science - they are trying to explain the rain with reference to the fact it's March. \n",
    "\n",
    "Let's assign some variables: \n",
    "\n",
    "- H - It's raining in Vancouver\n",
    "- E - It's March\n",
    "\n",
    "It rains most days in March - 20 out of 30, in the average year. So the probability that it's raining in Vancouver, given that it's March ($P(H|E)$) is $\\frac{20}{30}$ or $\\frac{2}{3}$. \n",
    "\n",
    "By contrast $P(E|H)$, the probability that it's March given that it is raining, is low. It also rains a lot in other months. First, of all there are 12 of them. Second, the winter months are extremely rainy also. So if you only knew that it's raining, it wouldn't give you very compelling evidence that the month was November. So the two terms are not not equal.\n",
    "\n",
    "$$ P(H|E) \\neq P(E|H) $$\n",
    "\n",
    "Despite not being equal, we should think they are proportional. As your hypothesis does a better and better job predicting the data (i.e. as $P(E|H)$ goes up), that seems to suggest your hypothesis is more likely to be true. Take just the extreme cases. If your hypothesis always predicts how the data should look, you would start to think your hypothesis is right. If your hypothesis never gets the data right, you should think it's wrong. So they should be proportional but not equal. We need to find some more components that moderate this relationship so we get the right numbers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cEZvu_WjAfRQ",
   "metadata": {
    "id": "cEZvu_WjAfRQ"
   },
   "source": [
    "\n",
    "## The actual theorem\n",
    "\n",
    "There is a theorem of probability that does just this. If we multiply and divide the $P(E|H)$ term by two other numbers, we get the right relationship. The 3blue1brown video does a good job of unpacking the theorem and providing some motivation for it. I'll let you turn to that video if you haven't done so already.\n",
    "\n",
    "$$ P(H|E) = P(H) \\frac{P(E|H)}{P(E)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lzIhI94mAc4Z",
   "metadata": {
    "id": "lzIhI94mAc4Z"
   },
   "source": [
    "## Bayes theorem as a learning algorithm\n",
    "\n",
    "Bayes theorem is tremendously important to modern science so you'll want to get an intuition for it another of different ways. The video emphasizes visual techniques for intuitions. A second way to get an intuition for the rule is to interpret it as a kind of learning process. Suppose you have some idea - that it's raining right now. You aren't sure your idea is right but you have some confidence in it. If you are really confidence, we'll say $P(H) \\approx 1$. If you are totally unsure, we'll say $P(H) \\approx \\frac{1}{2}$. If you really doubt your idea is right we'll say $P(H) \\approx 0$. It doesn't particularly matter where you start your confidence. But we call this initial level of confidence a *prior*.\n",
    "\n",
    "Now you get some bit of evidence for the idea - someone reminds you it's March. What should your confidence in your idea be after learning the evidence be? That is represented by $P(H|E)$. We call this number a *posterior*. The posterior is usually what we are trying to find in science.\n",
    "\n",
    "To find your new level of confidence, you take the old level of confidence and multiply it by the ratio $\\frac{P(E|H)}{P(E)}$. The top number represent the probability of the evidence, given your hypothesis. You've seen this plenty of times already. It's same the number we find when we calculate p-values. You can use techniques like the binomial theorem or the normal distribution to find it. We'll call it the *likelihood*. \n",
    "\n",
    "The bottom number represents a kind of baseline probability for finding the evidence, with or without the hypothesis. We'll call it the *expectation*. When this ratio is greater than one, your confidence should grow. When the ratio is less than one, your confidence should shrink. The intuition is that when the hypothesis says the evidence should show up more often than you would normally anticipate the evidence, the hypothesis must be onto something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rPS14T8iAYAe",
   "metadata": {
    "id": "rPS14T8iAYAe"
   },
   "source": [
    "## The Law of Total Probability\n",
    "\n",
    "In practice, we rarely can find the expectation directly. We would have to know how often events like the evidence show up *in general*. Instead, we use the law of total probability to find the expectation. The law says the probability of one event is equal to a weighted average of all the possible ways for that event to happen. The video employs the simple law of total probability where there are two possible scenarios. But suppose there are $n$ different ways for the event to happen, then the average probability of the event is:\n",
    "\n",
    "$$ P(E) = \\sum_{i=1}^{n} P(E|H_i)P(H_i) $$\n",
    "\n",
    "Each scenario for producing the event is an $i$. On a given scenario, we want to know how often that scenario comes up $P(H_i)$ and the probability of the event, given the scenario, or $P(E|H_i)$. Suppose I want to know how often it rains. One way to discover that is to count the number of days of rain in a year and divide by 365. But another way is to count the number of days it rains in each month, divide by 30 or 31, add up the frequencies from each month and divide by 12. They both get you to the same place.\n",
    "\n",
    "What's clever about this approach is that we only need to know two kinds of terms - priors and likelihoods. The downside is that we'll need to work through a lot of prior/likelihood combinations to find our answers. But that's what computers are for.\n",
    "\n",
    "The law of total probability gives us a new way to interpret Bayes theorem. If that last section didn't make sense, maybe this will. Let's say the likelihood, $P(E|H)$, is a measure of how good a hypothesis is. The ratio is bigger than 1 whenever the likelihood is better than the average likelihood. Now all Bayes theorem says is that hypotheses that are better than the average hypothesis should grow in probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F1VtpOMOATT-",
   "metadata": {
    "id": "F1VtpOMOATT-"
   },
   "source": [
    "## Check your understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UvZkuJY0BAKj",
   "metadata": {
    "id": "UvZkuJY0BAKj"
   },
   "source": [
    "### Steve\n",
    "\n",
    "*Suppose there is a village with 200 people. 20 of them are librarians. 180 of them are farmers. People in the village have one of two types of souls. Some people have a meek and tidy soul. Other people have an industrious and outgoing soul. 40% of librarians have a meek and tidy soul. 10% of farmers have meek and tidy souls.*\n",
    "\n",
    "*Now consider Steve. We know he has a meek and tidy soul. What's the probability he is a librarian?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LOdI580oEe1Y",
   "metadata": {
    "id": "LOdI580oEe1Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c_V96yrhEdWs",
   "metadata": {
    "id": "c_V96yrhEdWs"
   },
   "source": [
    "#### Hide this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rsiE4XF9BGaG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsiE4XF9BGaG",
    "outputId": "3ca9154c-f346-4001-eda4-74e6512d93e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p(meek and tidy soul | librarian) = p(e|h)\n",
    "# p(meek and tidy soul) = p(e)\n",
    "# p(steve is a librarian) = p(h)\n",
    "# p(steve is a librarian | meek and tidy soul) = p(h|e)\n",
    "\n",
    "prior = 20 / 200\n",
    "likelihood = 0.4\n",
    "expectation = (0.4 * 20 / 200) + (0.1 * 180 / 200)\n",
    "\n",
    "prior * likelihood / expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MwpXubISCFvN",
   "metadata": {
    "id": "MwpXubISCFvN"
   },
   "source": [
    "### Cab example\n",
    "\n",
    "*A cab was involved in a hit and run accident at night. Two cab companies, the Green and the Blue, operate in the city. You are given the following data:*\n",
    "\n",
    "*$85\\%$ of the cabs in the city are Green and $15\\%$ are Blue.\n",
    "A witness identified the cab as Blue. The court tested the reliability of the witness under the same circumstances that existed on the night of the accident and concluded that the witness correctly identified each one of the two colors $80\\%$ of the time and failed $20\\%$ of the time.*\n",
    "\n",
    "*What is the probability that the cab involved in the accident was blue rather green?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HPQ2KjMaEggM",
   "metadata": {
    "id": "HPQ2KjMaEggM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Tij1dA5rBbT4",
   "metadata": {
    "id": "Tij1dA5rBbT4"
   },
   "source": [
    "#### Hide this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gZ49f8TzCN2H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZ49f8TzCN2H",
    "outputId": "c0ddc4f7-74e3-43b8-9a2e-db7bf6dd77c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4137931034482758"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p(h|e) = p(blue car involved in the accident | witness says the cab is blue)\n",
    "# p(h) = p(blue car involved)\n",
    "# p(e | h) = p(witness says the cab is blue | the blue car was involved)\n",
    "# p(e) = p(witness says the cab is blue)\n",
    "\n",
    "prior_blue = 0.15\n",
    "likelihood_blue = 0.8\n",
    "\n",
    "prior_green = 0.85\n",
    "likelihood_green = 0.2\n",
    "\n",
    "# scenario 1 - the car is actually blue\n",
    "# sceario 2 - the car is actually green\n",
    "\n",
    "expectation = (prior_blue * likelihood_blue) + (prior_green * likelihood_green)\n",
    "\n",
    "prior_blue * likelihood_blue / expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5H6MtKXqAyRE",
   "metadata": {
    "id": "5H6MtKXqAyRE"
   },
   "source": [
    "### Christmas day at sea\n",
    "\n",
    ">It is Christmas Day and you are sailing in the North Atlantic. You observe that the barometer is falling more than 1mb per\n",
    "hour, so you are a bit worried that a storm is coming. According to the best available meteorological data, the probability that the barometer falls more than 1mb per hour given that a storm is coming is 0.95. The probability that it falls more than 1mb per hour given that a storm is not coming, however, is just 1 in 1,000. Furthermore, the probability that there\n",
    "is a storm in the North Atlantic any given day in December is 0.25. What is the probability that a storm is coming given that the barometer falls more than 1mb per hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85c3c3",
   "metadata": {
    "id": "0f85c3c3"
   },
   "outputs": [],
   "source": [
    "# write your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94fcd5",
   "metadata": {
    "id": "df94fcd5"
   },
   "source": [
    "#### Hide this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154cbefc",
   "metadata": {
    "code_folding": [],
    "id": "154cbefc",
    "outputId": "3cc0a252-b008-4fb3-c040-662cac363ed9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968520461699895"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Posterior? - p(storm|barometer falling) = ?\n",
    "# likelihood - p(barometer falling|storm) = 0.95\n",
    "# likelihood - p(barometer falling|no storm) = .001\n",
    "# prior - p(storm) = 0.25\n",
    "\n",
    "likelihood_1 = 0.95\n",
    "likelihood_2 = 0.001\n",
    "prior_1 = 0.25\n",
    "prior_2 = 0.75\n",
    "\n",
    "likelihood_1 * prior_1 / (likelihood_1 * prior_1 + likelihood_2 * prior_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qj8DPrIrFjXr",
   "metadata": {
    "id": "qj8DPrIrFjXr"
   },
   "source": [
    "### Three hypotheses\n",
    "\n",
    "*Suppose there is a village with 200 people. 20 of them are librarians. 140 of them are farmers. 40 of them are cooks. People in the village have one of two types of souls. Some people have a meek and tidy soul. Other people have an industrious and outgoing soul. 40% of librarians have a meek and tidy soul. 10% of farmers have meek and tidy souls. 20% of cooks have meek and tidy souls.*\n",
    "\n",
    "*Now consider Steve. We know he has a meek and tidy soul. What's the probability he is a librarian?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RrB1O_TRFsPn",
   "metadata": {
    "id": "RrB1O_TRFsPn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mm6ti6t5FshA",
   "metadata": {
    "id": "mm6ti6t5FshA"
   },
   "source": [
    "#### Hide this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rVBblI2_Ft_-",
   "metadata": {
    "id": "rVBblI2_Ft_-"
   },
   "outputs": [],
   "source": [
    "prior_librarian = 20 / 200\n",
    "likelihood_librarian = 0.4\n",
    "\n",
    "prior_cook = 40 / 200\n",
    "likelihood_cook = 0.2\n",
    "\n",
    "prior_farmer = 140 / 200\n",
    "likelihood_farmer = 0.1\n",
    "\n",
    "prior_librarian * likelihood_librarian / (prior_librarian * likelihood_librarian + \n",
    "                                          prior_cook * likelihood_cook + \n",
    "                                          prior_farmer * likelihood_farmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616964af",
   "metadata": {
    "id": "616964af"
   },
   "source": [
    "# Posterior distributions\n",
    "\n",
    "In the last section, we tried to find the probability of just one hypothesis. This makes sense given the kinds of hypotheses we were looking at - a storm is either coming or it's not, it's either raining or it's not. But most scientific problems are not like that. There numerous possibilities. So our goal is to find a distribution of probabilities over the set of possible hypotheses. This tells us how good each hypothesis relative to all the others. \n",
    "\n",
    "Suppose I want to know what percent of Earth's surface is water. I might try to carefully measure the areas of each ocean. But that's hard. The oceans are not nice shapes with known area formula. Instead, I might try Bayesian estimation. I toss the globe up and down. Every time I catch the globe, I write down whether my thumb is on the water or the land. I throw the globe 9 times. I find 6 counts of water and 3 counts of land. \n",
    "\n",
    "We'll try solving this problem in a number of ways and slowly work out way up to nice computing tricks for finding posterior distributing. The first thing to notice is that this is problem well represented by the binomial distribution. There are two outcomes, water and land. Each trial has the same probability of turning up water or land. We've already learned we can use the binomial distribution to find $P(E|H)$. We did that when calculating p-values last week.\n",
    "\n",
    "Let's suppose my hypothesis is that the earth is 50% water. Let's remind ourselves how we calculate likelihoods from the binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33097865",
   "metadata": {
    "id": "33097865"
   },
   "outputs": [],
   "source": [
    "# packages we'll need\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_bristol(a,n):\n",
    "    '''Returns a list of 0s and 1s of lengeth n\n",
    "    with 0 indicating failure and 1 indicating success.\n",
    "    \n",
    "    a = accuracy on each cup\n",
    "    n = the number of cups'''\n",
    "\n",
    "    experiment = []\n",
    "\n",
    "    for i in range(n):\n",
    "        \n",
    "        outcome = np.random.choice([1,0],p=[a,1-a])\n",
    "        experiment.append(outcome)\n",
    "        \n",
    "    return experiment\n",
    "\n",
    "def run_experiments(a,n,precision):\n",
    "    '''Returns a list containing the number of cups lady bristol\n",
    "    guessed correctly over many experiments\n",
    "    \n",
    "    a = accuracy on each cup\n",
    "    n = number of cups per experiment\n",
    "    precision = the number of experiments'''\n",
    "    \n",
    "    \n",
    "    all_trials = []\n",
    "\n",
    "    for i in range(precision):\n",
    "\n",
    "        correct = sum(simulate_bristol(a,n))\n",
    "        all_trials.append(correct)\n",
    "\n",
    "    return all_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ede70c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5ede70c",
    "outputId": "c45eae7e-0915-4d98-97bf-26302d6a4c42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1654"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our binomial distribution code\n",
    "# from the lady tasting tea problem\n",
    "\n",
    "a = 0.5\n",
    "n = 9\n",
    "k = 6\n",
    "precision = 10000\n",
    "\n",
    "all_trials = run_experiments(a,n,precision)\n",
    "matches = all_trials.count(k)\n",
    "prob = matches / precision\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5d868",
   "metadata": {
    "id": "d3d5d868"
   },
   "source": [
    "This is a good start. But we have a lot of unknown terms.\n",
    " \n",
    "$$ P(H|E) = P(H) \\frac{0.164}{\\sum_{i=1}^{n} P(E|H_i)P(H_i)} $$\n",
    "\n",
    "To find them, we need to imagine at least one other hypothesis. When we have multiple hypotheses, we can use our law of total probability trick to the denominator. So let's say $H_2$ - the earth is 60% water. We can easily find the likelihood with the same process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22837c53",
   "metadata": {
    "id": "22837c53",
    "outputId": "2c23461c-5c51-45da-a7fc-371d494e2ab6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.6 # this is the key change\n",
    "n = 9\n",
    "k = 6\n",
    "precision = 10000\n",
    "\n",
    "all_trials = run_experiments(a,n,precision)\n",
    "matches = all_trials.count(k)\n",
    "prob = matches / precision\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9258b4",
   "metadata": {
    "id": "aa9258b4"
   },
   "source": [
    "We'll also need to assign prior probabilities to each hypothesis. We'll have a lot to say about how to assign priors shortly, but let's just assign equal probability to each option.\n",
    "\n",
    "- $P(H_1) = \\frac{1}{2}$\n",
    "\n",
    "- $P(H_2) = \\frac{1}{2}$\n",
    "\n",
    "Now we can solve Bayes theorem for the posterior of each hypothesis.\n",
    "\n",
    "$$ P(H_1|E) = P(H_1) \\frac{P(E|H_1)}{P(H_1)P(E|H_1) + P(H_2)P(E|H_2)} $$\n",
    "\n",
    "Plugging in our numbers\n",
    "\n",
    "$$ P(H_1|E) = 0.5 \\frac{0.164}{0.5*0.164+0.5*0.25} $$\n",
    "\n",
    "$$ P(H_1|E) = \\frac{0.082}{0.082 + 0.125} $$\n",
    "\n",
    "$$ P(H_1|E) = \\frac{0.082}{0.207} $$\n",
    "\n",
    "$$ P(H_1|E) = 0.39 $$\n",
    "\n",
    "When there are only two hypotheses, the posterior for the other hypothesis is just $1 - P(H_1|E)$ or 0.61. So the conclusion of our analysis is there is 39% chance the earth is 50% water and a 61% chance that the earth is 60% water. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jhLmYfkuGXt2",
   "metadata": {
    "id": "jhLmYfkuGXt2"
   },
   "source": [
    "## Likelihood function\n",
    "\n",
    "We are going to be calculating a lot of likelihoods at this point in the class. So let's wrap out likelihood code into a function to make computations clearer as we get further along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "EDzStsdEGn4m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDzStsdEGn4m",
    "outputId": "aad5fb3e-2acb-45fa-d79b-dc40d9ba05b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1633"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood_tea(a,n,k,precision):\n",
    "    '''\n",
    "    Compute the likelihood of getting k successes out of n\n",
    "    trials assuming probability of success a on each trial.\n",
    "\n",
    "\n",
    "    a = accuracy\n",
    "    n = total number of trials\n",
    "    k = the number of successes\n",
    "    precision = the number of simulated experiments used to estimate\n",
    "    the likelihood'''\n",
    "\n",
    "    all_trials = run_experiments(a,n,precision)\n",
    "    matches = all_trials.count(k)\n",
    "    prob = matches / precision\n",
    "\n",
    "    return prob\n",
    "\n",
    "\n",
    "likelihood_tea(0.5,9,6,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gamU7NeLGVex",
   "metadata": {
    "id": "gamU7NeLGVex"
   },
   "source": [
    "## Generalizing to many hypotheses\n",
    "\n",
    "This result makes sense in one respect. Our sample was $\\frac{2}{3}$ water, so we should think that the 60% water hypothesis should do better than the 50% water hypothesis. But it doesn't matter sense in another. These numbers seem too high. Surely, we should not be *that* confidence that the earth is 60% water. If I remember my elementary school science, the number should be closer to 70% water. The problem is that we didn't test enough hypotheses. So we need to generalize this approach to more hypotheses. Let's try 10 hypotheses: every 10% increment from 10% to 100% of the world covered in water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9993c8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9993c8c",
    "outputId": "8b7f82ac-74c4-478d-80ae-a8858db56341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.003675344563552833,\n",
       " 0.023991832567636547,\n",
       " 0.07677386421643696,\n",
       " 0.16089841755997955,\n",
       " 0.24910668708524758,\n",
       " 0.2628892291985707,\n",
       " 0.17958141909137315,\n",
       " 0.04308320571720266,\n",
       " 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = [.1,.2,.3,.4,.5,.6,.7,.8,.9,1] # a list containing each of our hypotheses.\n",
    "\n",
    "# let's find the likelihood of the data by momentarily\n",
    "# assuming each hypothesis is true and then working\n",
    "# through our binomial simulation code.\n",
    "\n",
    "n = 9\n",
    "k = 6\n",
    "precision = 10000\n",
    "\n",
    "likelihoods = [likelihood_tea(h,n,k,precision) for h in hypotheses]\n",
    "\n",
    "# now we just need priors. Again, we'll assume each hypothesis has the same initial credibility.\n",
    "# we need a list containing 10 probabilities that sum to 1.\n",
    "priors = [1/10] * 10\n",
    "\n",
    "# now we need to multipy each likelihood by it's respective prior.\n",
    "\n",
    "posteriors = []\n",
    "for i in range(10):\n",
    "    posterior = priors[i] * likelihoods[i]\n",
    "    posteriors.append(posterior)\n",
    "    \n",
    "# these posteriors haven't been divided by the expectation yet. Let's do that.\n",
    "# it turns out we can just sum the list of the posteriors to get the average likelihood i.e the expectation.\n",
    "\n",
    "expectation = sum(posteriors)\n",
    "\n",
    "posteriors = [i / expectation for i in posteriors]\n",
    "posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6905a3",
   "metadata": {
    "id": "ae6905a3"
   },
   "source": [
    "What we've just calculated is a posterior distribution. Let's plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8604f565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "8604f565",
    "outputId": "d41ece99-b26f-4c7f-d350-ee09f4875324"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hypotheses, posteriors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2f7e3",
   "metadata": {
    "id": "f1e2f7e3"
   },
   "source": [
    "This looks a lot better. We knew the earth was probably around 70% water. This plot places the majority of the posterior distribution in that area. In other words, the most likely hypothesis for how much water there is looks to be 70%, quickly followed by 60%. \n",
    "\n",
    "As an achievement of logical, this is really impressive. We estimated the surface area of water on the earth using only sampling and probability theory. No rulers involved. This is why people like Bayes theorem so much. It lets us estimate basically any quantity we want. All we need is a likelihood function (the binomial distribution) and a prior distribution over some range of hypotheses."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
